{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/root/persistence_data')\n",
    "import _setup\n",
    "# Config\n",
    "from TechfinTorchAPI.config import *\n",
    "from logger import get_logger\n",
    "from TechfinDataAPI.utils.reader import pkl_reader\n",
    "# Data\n",
    "from TechfinTorchAPI.dataloader.pandas_dataloader import PandasDataset\n",
    "from TechfinTorchAPI.dataloader.tensor_dataset import TensorListDataset\n",
    "# Training Structure\n",
    "from TechfinTorchAPI.engine.hooks import *\n",
    "from TechfinTorchAPI.engine.trainer import SimpleTrainer\n",
    "# Losses\n",
    "from TechfinTorchAPI.models import *\n",
    "from TechfinTorchAPI.components.loss import *\n",
    "# eval\n",
    "from TechfinTorchAPI.matrics.pandas_matrics import my_IC, my_IR\n",
    "from TechfinTorchAPI.engine.BT_system import BTSystem\n",
    "from TechfinDataAPI.utils.decorator import time_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 超参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "#       Hyperparameters\n",
    "#####################################\n",
    "eval_period = 300\n",
    "test_batch_size = 1\n",
    "result_path = '/root/persistence_data/TechfinTorch/example/LSTM_result_along_2layers'\n",
    "_hidden_size = 64\n",
    "_device = 'cuda'\n",
    "iter_num = 5000\n",
    "_optimizer = 'adam'\n",
    "_num_layer = 1\n",
    "learning_rate = 0.0001\n",
    "training_batch_size = 100\n",
    "_loss_func = '*'\n",
    "checkpoint_freq = eval_period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取数据（Tensor List）[训练测试数据]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = t.load('*')\n",
    "test_data = t.load('*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, torch.Tensor)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorListDataset(train_data, lambda x: (x[:,:-2].type(t.float32), x[:,-1].type(t.float32)))\n",
    "test_dataset = TensorListDataset(test_data, lambda x: (x[:,:-2].type(t.float32), x[:,-1].type(t.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TechfinTorchAPI.dataloader.tensor_dataset.TensorListDataset at 0x7f45f41b6ca0>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to('cuda')\n",
    "test_dataset.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1000, shuffle = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回测数据读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 14:22:57,955 - [<module>] - INFO: Data reading finishes\n"
     ]
    }
   ],
   "source": [
    "logger = get_logger(__name__)\n",
    "train_data_ = pkl_reader('*')\n",
    "test_data_ = pkl_reader('*')\n",
    "logger.info('Data reading finishes')\n",
    "train_dataset_ = PandasDataset(train_data_, \n",
    "                              None, # 需要被截面标准化的cols\n",
    "                              lambda x: (x.iloc[:,:-2], x.iloc[:,-1])) #输出前的transform_method。只输出因子还有label_2\n",
    "test_dataset_ = PandasDataset(test_data_,\n",
    "                            None,\n",
    "                            lambda x: (x.iloc[:,:-2], x.iloc[:,-1])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_feat = len(train_data_.columns) - 2\n",
    "model = Model(d_feat = d_feat,\n",
    "                  hidden_size = _hidden_size,\n",
    "                  num_layers = _num_layer,\n",
    "                  dropout = 0.3,\n",
    "                  only_end=False).to(_device)\n",
    "\n",
    "if _optimizer == 'adam':\n",
    "    optimizer = optim.Adam(model_lstm.parameters(), lr = learning_rate)\n",
    "elif _optimizer == 'SGD':\n",
    "    optimizer = optim.SGD(model_lstm.parameters(), lr = learning_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 15:12:58,719 - [<module>] - INFO: Now the Training Process starts. 5000 max Iterations\n",
      "2021-10-20 15:12:58,724 - [train] - INFO: start training from the epoch 0\n",
      "2021-10-20 15:12:58,728 - [before_train] - INFO: Model LSTMModel starts training at Wed Oct 20 15:12:58 2021\n",
      "  0%|          | 1/5000 [00:00<09:54,  8.41it/s, loss=tensor(-0.0804), average_loss=tensor(-8.0445e-05)]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------+\n",
      "|     Modules      | Parameters |\n",
      "+------------------+------------+\n",
      "| rnn.weight_ih_l0 |   22016    |\n",
      "| rnn.weight_hh_l0 |   16384    |\n",
      "|  rnn.bias_ih_l0  |    256     |\n",
      "|  rnn.bias_hh_l0  |    256     |\n",
      "|  fc_out.weight   |     64     |\n",
      "|   fc_out.bias    |     1      |\n",
      "+------------------+------------+\n",
      "Total Trainable Params: 38977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-10-20 15:13:33,998 - [_do_eval] - INFO: Eval results at iterations 299: {'label_1_IR': 0.06099583704713495, 'label_2_IR': 0.0712840577306617}\n",
      "2021-10-20 15:13:34,113 - [after_step] - INFO: Test Loss at iterations 299: -0.07414558529853821\n",
      "2021-10-20 15:14:09,478 - [_do_eval] - INFO: Eval results at iterations 599: {'label_1_IR': -0.0013868054391489844, 'label_2_IR': 0.06884406135267125}\n",
      "2021-10-20 15:14:32,210 - [_do_eval] - INFO: Eval results at iterations 599: {'label_1_IR': -0.0013868054391489844, 'label_2_IR': 0.06884406135267125}\n"
     ]
    }
   ],
   "source": [
    "    logger.info('Now the Training Process starts. {} max Iterations'.format(iter_num))\n",
    "    trainer = SimpleTrainer(    model,\n",
    "                                train_loader,\n",
    "                                optimizer,\n",
    "                                _loss_func,\n",
    "                                )\n",
    "    back_testing_sys = BTSystem(test_dataset_)\n",
    "    back_testing_sys.register({'label_1_IR': my_IR('prediction', 'label_1'),\n",
    "                               'label_2_IR': my_IR('prediction', 'label_2')})\n",
    "    back_testing_sys2 = BTSystem(train_dataset_)\n",
    "    back_testing_sys2.register({'label_1_IR_Training': my_IR('prediction', 'label_1'),\n",
    "                               'label_2_IR_Training': my_IR('prediction', 'label_2')})\n",
    "    trainer.register_hooks([    \n",
    "                                TqdmHookBase(period = 2),\n",
    "                                CustomEvalHook(period = eval_period,\n",
    "                                            eval_functions = {\n",
    "                                                'IR_test,train':back_testing_sys,\n",
    "                                            }),\n",
    "                                CustomEvalHook(period = 2*eval_period,\n",
    "                                            eval_functions = {\n",
    "                                                'IR_test,train':back_testing_sys2,\n",
    "                                            }),\n",
    "                                BatchValLossHook(test_dataloader= test_loader,\n",
    "                                                period =eval_period,\n",
    "                                                test_batchsize = test_batch_size),\n",
    "                                CheckpointHook(result_path = result_path, \n",
    "                                            period = checkpoint_freq),\n",
    "                                BestModelHook(result_path = result_path),\n",
    "                                IterationWriterHook( result_path, eval_period)])\n",
    "\n",
    "    trainer.train(iter_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8cb48ee34b52abbc0c4c6c9a8d1e18bbd374f2d1391cafbd22bf8a5424951de7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}